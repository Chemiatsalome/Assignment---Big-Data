version: '3'
services:
  
    node-red:
      image: nodered/node-red
      container_name: nodered
      volumes:
        - nodered_data:/data
      ports:
        - "1881:1880"

    namenode:
      image: bde2020/hadoop-namenode:latest # 2.0.0-hadoop2.7.4-java8
      container_name: namenode
      volumes:
        - /tmp/hdfs/namenode:/hadoop/dfs/name
      environment:
        - CLUSTER_NAME=bd-iot
      env_file:
        - ./configs/hadoop-hive.env
      ports:
        - "50070:50070"

    datanode:
      image: bde2020/hadoop-datanode:latest # 2.0.0-hadoop2.7.4-java8
      container_name: datanode
      volumes:
        - /tmp/hdfs/datanode:/hadoop/dfs/data
        #- ./bank:/bank
      env_file:
        - ./configs/hadoop-hive.env
      environment:
        SERVICE_PRECONDITION: "namenode:50070"
      depends_on:
        - namenode
      ports:
        - "50075:50075"

    hive-server:
      image: bde2020/hive:latest # 2.3.2-postgresql-metastore
      container_name: hive-server
      env_file:
        - ./configs/hadoop-hive.env
      environment:
        HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
        SERVICE_PRECONDITION: "hive-metastore:9083"
      ports:
        - "10000:10000"
      depends_on:
        - hive-metastore

    hive-metastore:
      image: bde2020/hive:latest # 2.3.2-postgresql-metastore
      container_name: hive-metastore
      env_file:
        - ./configs/hadoop-hive.env
      command: /opt/hive/bin/hive --service metastore
      environment:
        SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
      ports:
        - "9083:9083"
      depends_on:
        - hive-metastore-postgresql

    hive-metastore-postgresql:
      image: bde2020/hive-metastore-postgresql:latest # 2.3.0
      container_name: hive-metastore-postgresql
      depends_on:
        - datanode

    spark-master:
      image: bde2020/spark-master:latest # 2.4.0-hadoop2.7
      container_name: spark-master
      ports:
        - 8080:8080
        - 7077:7077
      environment:
        - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      env_file:
        - ./configs/hadoop-hive.env

    spark-worker:
      image: bde2020/spark-worker:latest # 2.4.0-hadoop2.7
      container_name: spark-worker
      environment:
        - SPARK_MASTER=spark://spark-master:7077
        - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
        - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore
      depends_on:
        - spark-master
      ports:
        - 8081:8081
      env_file:
        - ./configs/hadoop-hive.env

    zeppelin:
      image: openkbs/docker-spark-bde2020-zeppelin
      container_name: zeppelin
      environment:
        CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
        SPARK_MASTER: "spark://spark-master:7077"
        MASTER: "spark://spark-master:7077"
        SPARK_MASTER_URL: spark://spark-master:7077
        ZEPPELIN_PORT: 8080
        ZEPPELIN_JAVA_OPTS:
          -Dspark.driver.memory=1g
          -Dspark.executor.memory=2g
      ports:
        - 19090:8080
      env_file:
        - ./configs/hadoop-hive.env
      volumes:
        - /tmp/simple-demo/zeppelin/data:/usr/lib/zeppelin/data:rw
        - /tmp/simple-demo/zeppelin/notebook:/usr/lib/zeppelin/notebook:rw
      command: /usr/lib/zeppelin/bin/zeppelin.sh

    hue:
      image: gethue/hue:latest # 20191107-135001
      hostname: hue
      container_name: hue
      dns: 8.8.8.8
      ports:
      - "8888:8888"
      volumes:
        - ./configs/hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue.ini
      depends_on:
      - "database"

    database:
      image: mysql:latest # 5.7
      container_name: database
      ports:
          - "33061:3306"
      command: --init-file /data/application/init.sql
      volumes:
          - /tmp/mysql/data:/var/lib/mysql
          - ./init.sql:/data/application/init.sql
      environment:
          MYSQL_ROOT_USER: root
          MYSQL_ROOT_PASSWORD: secret
          MYSQL_DATABASE: hue
          MYSQL_USER: root
          MYSQL_PASSWORD: secret

    streamsets:
      image: streamsets/datacollector:3.13.0-latest
      container_name: streamsets
      ports:
        - "18630:18630"

    zookeeper:
      image: 'bitnami/zookeeper:latest'
      container_name: zookeeper
      ports:
        - '2181:2181'
      environment:
        - ALLOW_ANONYMOUS_LOGIN=yes

    kafka:
      image: 'bitnami/kafka:latest'
      container_name: kafka
      ports:
        - '9092:9092'
      environment:
        - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
        - ALLOW_PLAINTEXT_LISTENER=yes
        - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
        - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
        - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://localhost:9093
        - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
        - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
        # - KAFKA_BROKER_ID=1
      depends_on:
        - zookeeper

    # create kafka IoT topic
    kafka-init:
      image: 'bitnami/kafka:latest'
      container_name: kafka-init
      command: [ "/bin/bash", "-c", "chmod +x /kafka_topic.sh && sh /kafka_topic.sh"]
      environment:
        - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
        - IOT_TOPIC_NAME=iot-temp
      depends_on:
        - kafka
      volumes:
        - type: bind
          source: ./configs/kafka_topic.sh
          target: /kafka_topic.sh
      init: true

volumes:
    nodered_data: {}
