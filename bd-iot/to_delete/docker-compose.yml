version: '3'
services:

  namenode:
    image: owuor/hdfs-namenode
    container_name: hdfs-namenode
    ports:
        - "1881:1880"
      networks:
        - net_bd

    #namenode:
    #  image: bde2020/hadoop-namenode:latest # 2.0.0-hadoop2.7.4-java8
    #  container_name: namenode
    #  volumes:
    #    - /tmp/hdfs/namenode:/hadoop/dfs/name
    #  environment:
    #    - CLUSTER_NAME=bd-iot
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  ports:
    #    - "50070:50070"
    #  networks:
    #    - net_bd
    
    #datanode:
    #  image: bde2020/hadoop-datanode:latest # 2.0.0-hadoop2.7.4-java8
    #  container_name: datanode
    #  volumes:
    #    - /tmp/hdfs/datanode:/hadoop/dfs/data
        #- ./bank:/bank
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  environment:
    #    SERVICE_PRECONDITION: "namenode:50070"
    #  depends_on:
    #    - namenode
    #  ports:
    #    - "50075:50075"
    #  networks:
    #    - net_bd

    #hive-server:
    #  image: bde2020/hive:latest # 2.3.2-postgresql-metastore
    #  container_name: hive-server
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  environment:
    #    HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
    #    SERVICE_PRECONDITION: "hive-metastore:9083"
    #  ports:
    #    - "10000:10000"
    #  depends_on:
    #    - hive-metastore
    #  networks:
    #    - net_bd

    #hive-metastore:
    #  image: bde2020/hive:latest # 2.3.2-postgresql-metastore
    #  container_name: hive-metastore
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  command: /opt/hive/bin/hive --service metastore
    #  environment:
    #    SERVICE_PRECONDITION: "namenode:50070 datanode:50075 hive-metastore-postgresql:5432"
    #  ports:
    #    - "9083:9083"
    #  depends_on:
    #    - hive-metastore-postgresql
    #  networks:
    #    - net_bd

    #hive-metastore-postgresql:
    #  image: bde2020/hive-metastore-postgresql:latest # 2.3.0
    #  container_name: hive-metastore-postgresql
    #  depends_on:
    #    - datanode
    #  networks:
    #    - net_bd

    #spark-master:
    #  image: bde2020/spark-master:latest # 2.4.0-hadoop2.7
    #  container_name: spark-master
    #  ports:
    #    - 8080:8080
    #    - 7077:7077
    #  environment:
    #    - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  networks:
    #    - net_bd

    #spark-worker:
    #  image: bde2020/spark-worker:latest # 2.4.0-hadoop2.7
    #  container_name: spark-worker
    #  environment:
    #    - SPARK_MASTER=spark://spark-master:7077
    #    - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    #    - HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore/metastore
    #  depends_on:
    #    - spark-master
    #  ports:
    #    - 8081:8081
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  networks:
    #    - net_bd

    #zeppelin:
    #  image: openkbs/docker-spark-bde2020-zeppelin
    #  container_name: zeppelin
    #  environment:
    #    CORE_CONF_fs_defaultFS: "hdfs://namenode:8020"
    #    SPARK_MASTER: "spark://spark-master:7077"
    #    MASTER: "spark://spark-master:7077"
    #    SPARK_MASTER_URL: spark://spark-master:7077
    #    ZEPPELIN_PORT: 8080
    #    ZEPPELIN_JAVA_OPTS:
    #      -Dspark.driver.memory=1g
    #      -Dspark.executor.memory=2g
    #  ports:
    #    - 19090:8080
    #  env_file:
    #    - ./configs/hadoop-hive.env
    #  volumes:
    #    - /tmp/simple-demo/zeppelin/data:/usr/lib/zeppelin/data:rw
    #    - /tmp/simple-demo/zeppelin/notebook:/usr/lib/zeppelin/notebook:rw
    #  command: /usr/lib/zeppelin/bin/zeppelin.sh
    #  networks:
    #    - net_bd

    #hue:
    #  image: gethue/hue:latest # 20191107-135001
    #  hostname: hue
    #  container_name: hue
    #  dns: 8.8.8.8
    #  ports:
    #  - "8888:8888"
    #  volumes:
    #    - ./configs/hue-overrides.ini:/usr/share/hue/desktop/conf/z-hue.ini
    #  depends_on:
    #  - hue-database
    #  networks:
    #    - net_bd

    #hue-database:
    #  image: mysql:latest # 5.7
    #  container_name: hue-database
    #  ports:
    #      - "33061:3306"
    #  command: --init-file /data/application/init.sql
    #  volumes:
    #      - /tmp/mysql/data:/var/lib/mysql
    #      - ./init.sql:/data/application/init.sql
    #  environment:
    #      MYSQL_ROOT_USER: root
    #      MYSQL_ROOT_PASSWORD: secret
    #      MYSQL_DATABASE: hue
    #      MYSQL_USER: root
    #      MYSQL_PASSWORD: secret
    #  networks:
    #    - net_bd

    streamsets:
      image: streamsets/datacollector:3.13.0-latest
      container_name: streamsets
      ports:
        - "18630:18630"
      networks:
        - net_bd

    zookeeper:
      image: 'bitnami/zookeeper:latest'
      container_name: zookeeper
      ports:
        - '2181:2181'
      environment:
        - ALLOW_ANONYMOUS_LOGIN=yes
      networks:
        - net_bd

    kafka:
      image: 'bitnami/kafka:latest'
      container_name: kafka
      ports:
        - '9092:9092'
      environment:
        - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
        - ALLOW_PLAINTEXT_LISTENER=yes
        - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CLIENT:PLAINTEXT,EXTERNAL:PLAINTEXT
        - KAFKA_CFG_LISTENERS=CLIENT://:9092,EXTERNAL://:9093
        - KAFKA_CFG_ADVERTISED_LISTENERS=CLIENT://kafka:9092,EXTERNAL://localhost:9093
        - KAFKA_INTER_BROKER_LISTENER_NAME=CLIENT
        - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
        # - KAFKA_BROKER_ID=1
      depends_on:
        - zookeeper
      networks:
        - net_bd

    # create kafka IoT topic
    kafka-init:
      image: 'bitnami/kafka:latest'
      container_name: kafka-init
      command: [ "/bin/bash", "-c", "chmod +x /kafka_topic.sh && sh /kafka_topic.sh"]
      environment:
      - "HADOOP_CONF_DIR=/etc/hadoop"
      - "USER=root"

  zeppelin:
    image: owuor/zeppelin
    container_name: zeppelin
    port:
      - "8083:8080"

