{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e770ba7",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "Information retrieval involves searching for words/text from document(s). Indexing (esp. inverted indexing) is used to improve the efficiency of these searches. This exercise demonstrates the main steps of constructing an **Inverted Index** for a sample document and illustrates a sample query that uses the index to retrieve **vocabulary term**. The content for the remainder of this guide is as follows.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Python Libraries](#libraries)  \n",
    "    1.1. [Installing Python Libraries](#lib-install)  \n",
    "    1.2. [Importing Python Libraries](#lib-import)  \n",
    "2. [Reading (dummy) Text File](#dataset)\n",
    "3. [Information Retrieval](#retrieval)  \n",
    "    3.1. [Remove Punctuation](#punctuation)  \n",
    "    3.2. [Tokenization](#tokenize)  \n",
    "    3.3. [Remove Stop-Words](#stop-words)  \n",
    "    3.4. [Construct Inverted-Index](#indexing)  \n",
    "    3.5. [Pose Query](#query)  \n",
    "4. [Exercise: Construct an Inverted Index for UCI Data set](#exercise)\n",
    "  \n",
    "    \n",
    "# 1. Python Libraries <a name=\"libraries\"></a>\n",
    "## 1.1. Install Python libraries <a name=\"lib-install\"></a>\n",
    "This exercise will requires the following **Python** libraries:\n",
    "\n",
    "<ul>\n",
    "    <li><strong>nltk:</strong> package for natural language processing.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb911bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Libraries (if not installed)\n",
    "#!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44981ab9",
   "metadata": {},
   "source": [
    "## 1.2. Import libraries <a name=\"lib-import\"></a>\n",
    "We import the **nltk** *word_tokenize()* function for the tokenization stage, also, we download *stop words* from the **nltk** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8624bf91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/owuorjnr/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/owuorjnr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b5730",
   "metadata": {},
   "source": [
    "# Reading (dummy) Text File <a name=\"dataset\"></a>\n",
    "In this section, we read dummy data from a sample text file and store it in a variable **text**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc7878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped over the lazy dog.\\nhello! how are you? I will be quick to jump over this.\\nthis is a Masters unit named \\'data mining, storage and retrieval\\'. the Masters course is named \"data science\". there are about 50 quick students in this class.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will open the file\n",
    "file = open('sample_3.txt', encoding='utf8')\n",
    "text = file.read()\n",
    "file.seek(0)\n",
    "text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f013e",
   "metadata": {},
   "source": [
    "# 3. Information Retrieval <a name=\"retrieval\"></a>\n",
    "This exercise is adopted from:\n",
    "\n",
    "1. [Create Inverted Index for File using Python](https://www.geeksforgeeks.org/create-inverted-index-for-file-using-python/)\n",
    "2. [Python: Inverted Index for dummies](http://mocilas.github.io/2015/11/18/Python-Inverted-Index-for-dummies/)\n",
    "\n",
    "\n",
    "## 3.1. Remove Punctuation <a name=\"punctuation\"></a>\n",
    "In this section, we remove punctuation marks, accents etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7733b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the quick brown fox jumped over the lazy dog \\nhello  how are you  i will be quick to jump over this \\nthis is a masters unit named  data mining  storage and retrieval   the masters course is named  data science   there are about 50 quick students in this class '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
    "for ele in text:  \n",
    "    if ele in punc:\n",
    "        text = text.replace(ele, \" \")         \n",
    "\n",
    "# to maintain uniformity\n",
    "text=text.lower()                    \n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037308e",
   "metadata": {},
   "source": [
    "## 3.2. Tokenization <a name=\"tokenize\"></a>\n",
    "In this section, we tokenize/split the text read from the sample file. We present 2 tokens:\n",
    "\n",
    "1. Tokens with positional postings.\n",
    "2. Tokens with document (standard) postings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2122cc16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'the'),\n",
       " (4, 'quick'),\n",
       " (10, 'brown'),\n",
       " (16, 'fox'),\n",
       " (20, 'jumped'),\n",
       " (27, 'over'),\n",
       " (32, 'the'),\n",
       " (36, 'lazy'),\n",
       " (41, 'dog'),\n",
       " (46, 'hello'),\n",
       " (53, 'how'),\n",
       " (57, 'are'),\n",
       " (61, 'you'),\n",
       " (66, 'i'),\n",
       " (68, 'will'),\n",
       " (73, 'be'),\n",
       " (76, 'quick'),\n",
       " (82, 'to'),\n",
       " (85, 'jump'),\n",
       " (90, 'over'),\n",
       " (95, 'this'),\n",
       " (101, 'this'),\n",
       " (106, 'is'),\n",
       " (109, 'a'),\n",
       " (111, 'masters'),\n",
       " (119, 'unit'),\n",
       " (124, 'named'),\n",
       " (131, 'data'),\n",
       " (136, 'mining'),\n",
       " (144, 'storage'),\n",
       " (152, 'and'),\n",
       " (156, 'retrieval'),\n",
       " (168, 'the'),\n",
       " (172, 'masters'),\n",
       " (180, 'course'),\n",
       " (187, 'is'),\n",
       " (190, 'named'),\n",
       " (197, 'data'),\n",
       " (202, 'science'),\n",
       " (212, 'there'),\n",
       " (218, 'are'),\n",
       " (222, 'about'),\n",
       " (228, '50'),\n",
       " (231, 'quick'),\n",
       " (237, 'students'),\n",
       " (246, 'in'),\n",
       " (249, 'this'),\n",
       " (254, 'class')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Positional postings\n",
    "\n",
    "def word_split(text):\n",
    "    pos_tokens = []\n",
    "    wcurrent = []\n",
    "    windex = None\n",
    "    for i, c in enumerate(text):\n",
    "        if c.isalnum():\n",
    "            wcurrent.append(c)\n",
    "            windex = i\n",
    "        elif wcurrent:\n",
    "            word = u''.join(wcurrent)\n",
    "            pos_tokens.append((windex - len(word) + 1, word))\n",
    "            wcurrent = []\n",
    "    if wcurrent:\n",
    "        word = u''.join(wcurrent)\n",
    "        pos_tokens.append((windex - len(word) + 1, word))\n",
    "    return pos_tokens\n",
    "\n",
    "pos_tokens = word_split(text)\n",
    "pos_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710f4826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumped',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog',\n",
       " 'hello',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " 'i',\n",
       " 'will',\n",
       " 'be',\n",
       " 'quick',\n",
       " 'to',\n",
       " 'jump',\n",
       " 'over',\n",
       " 'this',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'masters',\n",
       " 'unit',\n",
       " 'named',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'storage',\n",
       " 'and',\n",
       " 'retrieval',\n",
       " 'the',\n",
       " 'masters',\n",
       " 'course',\n",
       " 'is',\n",
       " 'named',\n",
       " 'data',\n",
       " 'science',\n",
       " 'there',\n",
       " 'are',\n",
       " 'about',\n",
       " '50',\n",
       " 'quick',\n",
       " 'students',\n",
       " 'in',\n",
       " 'this',\n",
       " 'class']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Standard Postings\n",
    "\n",
    "for i in range(1):\n",
    "    # this will convert the word into tokens\n",
    "    std_tokens = word_tokenize(text)\n",
    "std_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2233a32b",
   "metadata": {},
   "source": [
    "## 3.3. Remove Stop-Words <a name=\"stop-words\"></a>\n",
    "In this section, we use a *Stop List** provided by the **nltk** library to remove common/stop words from our tokenized text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8027d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quick', 'brown', 'fox', 'jumped', 'lazy', 'hello', 'quick', 'jump', 'masters', 'unit', 'named', 'data', 'mining', 'storage', 'retrieval', 'masters', 'course', 'named', 'data', 'science', '50', 'quick', 'students', 'class']\n",
      "\n",
      "[(4, 'quick'), (10, 'brown'), (16, 'fox'), (20, 'jumped'), (36, 'lazy'), (46, 'hello'), (76, 'quick'), (85, 'jump'), (111, 'masters'), (119, 'unit'), (124, 'named'), (131, 'data'), (136, 'mining'), (144, 'storage'), (156, 'retrieval'), (172, 'masters'), (180, 'course'), (190, 'named'), (197, 'data'), (202, 'science'), (228, '50'), (231, 'quick'), (237, 'students'), (254, 'class')]\n"
     ]
    }
   ],
   "source": [
    "# 1. Standard Tokens\n",
    "valid_std_tokens = [\n",
    "    word for word in std_tokens if not word in stopwords.words()]\n",
    "\n",
    "# 2. Position Tokens\n",
    "valid_pos_tokens = [\n",
    "    (index, word) for index,word in pos_tokens if not word in stopwords.words()]\n",
    "  \n",
    "print(valid_std_tokens)\n",
    "print()\n",
    "print(valid_pos_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d41b9",
   "metadata": {},
   "source": [
    "## 3.4. Construct Inverted-Index <a name=\"indexing\"></a>\n",
    "In this section, we build/construct an **Inverted Index** with positional postings.\n",
    "\n",
    "* As an assignment, construct a standard **Inverted Index** and pose a sample query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e74683d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quick': [4, 76, 231],\n",
       " 'brown': [10],\n",
       " 'fox': [16],\n",
       " 'jumped': [20],\n",
       " 'lazy': [36],\n",
       " 'hello': [46],\n",
       " 'jump': [85],\n",
       " 'masters': [111, 172],\n",
       " 'unit': [119],\n",
       " 'named': [124, 190],\n",
       " 'data': [131, 197],\n",
       " 'mining': [136],\n",
       " 'storage': [144],\n",
       " 'retrieval': [156],\n",
       " 'course': [180],\n",
       " 'science': [202],\n",
       " '50': [228],\n",
       " 'students': [237],\n",
       " 'class': [254]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Positional Postings\n",
    "inverted = {}\n",
    "for index, word in valid_pos_tokens:\n",
    "    locations = inverted.setdefault(word, [])\n",
    "    locations.append(index)\n",
    "    \n",
    "inverted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6384b5",
   "metadata": {},
   "source": [
    "## 3.5. Pose Query <a name=\"query\"></a>\n",
    "In this section, we pose a sample query that used the **Inverted Index** to return the documents together with the corresponding positions that the query term occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78428c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 76, 231}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing functools for reduce()\n",
    "import functools\n",
    "\n",
    "query = 'quick'\n",
    "\n",
    "words = [word for _, word in word_split(query) if word in inverted]\n",
    "#results = [set(inverted[word].keys()) for word in words]\n",
    "results = [set(inverted[word]) for word in words]\n",
    "answer = functools.reduce(lambda x, y: x & y, results) if results else []\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea83c49-a425-4654-8224-022b836583e7",
   "metadata": {},
   "source": [
    "# 4. Exercise: Construct an Inverted Index for UCI Data set <a name=\"exercise\"></a>\n",
    "The [Eco_dataset](Eco_dataset.csv) is retrieved from the [UCI Data Repository](#https://archive.ics.uci.edu/ml/datasets/Eco-hotel). The data (**Eco-hotel Data Set**): includes Online Textual Reviews from both online (e.g., TripAdvisor) and offline (e.g., Guests' book) sources from the Areias do Seixo Eco-Resort. Use this data set to:\n",
    "\n",
    "1. Construct an Inverted Index\n",
    "2. Pose a query on your *index created in part 1.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af3325f-fa6f-406d-897e-adf9fddbe2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
